---
title: "ENUNCIADO taller en grupo Mat3 GIN 2025-2026"
author: "Taller"
lang: es
format:
  html:
    theme: superhero
    toc: true
    toc_depth: 4
    html-math-method: katex
    code-tools: true
    code-fold: true
    collapse: true
    keep-md: true
    code-overflow: wrap
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warning = FALSE,cache=FALSE)
# packages
library(tidyverse)
```

# Instrucciones para el taller

Se entrega en grupos que deben de estar constituidos en la actividad de grupos. Los grupos son de 2 o 3 ESTUDIANTES, loa caso especiales consultadlos con el profesor para que los autorice.

**Enlaces y Bibliografía**

-   [R for data science, Hadley Wickham, Garret Grolemund.](https://r4ds.had.co.nz/)
-   [Fundamentos de ciencia de datos con R.](https://cdr-book.github.io/)
-   [Tablas avanzadas: kable, KableExtra.](https://haozhu233.github.io/kableExtra/awesome_table_in_html.html)
-   [Geocomputation with R, Robin Lovelace, Jakub Nowosad, Jannes Muenchow](https://r.geocompx.org/)
-   Apuntes de R-basico y tidyverse moodel MAT3.

## Objetivo MALLORCA

Leeremos los siguientes datos de la zona de etiqueta `mallorca` con el código siguiente:

```{r}
load("clean_data/mallorca/listing_common0.RData")
ls()
listings0 = listings_common0 %>%
  select(id, scrape_id, listing_url,
         neighbourhood_cleansed, price,
         number_of_reviews,
         review_scores_rating,
         review_scores_rating,
         review_scores_cleanliness,
         review_scores_location,
         review_scores_value,
         number_of_reviews,
         accommodates,
         bathrooms_text,
         bedrooms,
         beds,
         minimum_nights,
         description,
         latitude,
         longitude,
         property_type,
         room_type)
```


**listings**

Generamos la  tibble `listings0` con datos DE  8 periodos  DE  apartamentos de inside Airbnb de Mallorca Y  seleccionando cuantas variables nos parecen más interesantes.

Separararemos la fecha del scrapping que es en la que se observaron  los datos de cada apartamento  nos quedaremos con los apartamentos que aparecen en las 8 periodos "scrapeados".

```{r}
listings0= listings0 %>% 
  mutate(date=as.Date(substr(
    as.character(scrape_id),1,8),
    format="%Y%m%d"),
    .after=id)
```

Ahora  analizamos  las fechas de los scrapings y el número de veces que aparecen 
 cada  apartamentos.



```{r}
table(listings0$date)
```
Hay 8 periodos de scrapping y vamos a quedarnos con los apartamentos que aparecen en todos los periodos


Vemos que cada apartamento aparece 8 veces una por periodo.


```{r}
table(table(listings0$id))
```



Notemos que cada apartamento:

-   queda identificado por id y por date que nos da el periodo en la que apareció el dato.
-   así que cada apartamento aparece 8 veces ya que hemos elegido solo los apartamentos que aparecen en las 8 muestras.
-   Las muestras son `r unique(listings0$date)`,

```{r}
unique(listings0$date)
```

**reviews**

Estos datos necesitan leerse de forma adecuada, las columnas 1, 2 y 4 deben ser de tipo `character` las otras son correctas

```{r}
reviews=read_csv("data/mallorca/2025-09-21/reviews.csv.gz")
str(reviews)
head(reviews)
```

**neighbourhoods.csv**

Son dos columnas y la primera es una agrupación de municipios (están NA) y la segunda es el nombre del municipio

```{r}
municipios=read_csv("data/mallorca/2025-09-21/neighbourhoods.csv")
str(municipios)
head(municipios)
```

**neighbourhoods.geojson**

Es el mapa de Mallorca, o podemos leer así:

```{r}
library(sf)
library(tmap)

# Leer el archivo GeoJSON
geojson_sf <- sf::st_read("data/mallorca/2025-09-21/neighbourhoods.geojson")

# Crear un mapa

# interactivo
tmap_mode("plot") # Cambiar a modo  view/plot   que es interactivo/estático
tm_shape(geojson_sf) +
  tm_polygons(col = "cyan", alpha = 0.6) +
  tm_layout(title = "Mapa - GeoJSON Mallorca con municipios")
```

Tenéis que consultar en la documentación de inside Airbnb para saber que significa cada variable. Os puede ser útil leer los ficheros [DATA_ABB_modelo_de_datos.html](DATA_ABB_modelo_de_datos.html) y [DATA_ABB_modelo_de_datos.pdf](DATA_ABB_modelo_de_datos.html) en los que se explica el modelo de datos de inside Airbnb y como se cargan en el espacio de trabajo.

Responder las siguientes preguntas con formato Rmarkdown (.Rmd) o quarto (.qmd) y entregad la fuente un fichero en formato html como salida del informe. Se puntúa la claridad de la respuesta, la calidad de la redacción y la corrección de la respuesta.

## Pregunta 1 (**1punto**)

Del fichero con los datos de listings `listings0` calcula los estadísticos descriptivos de las variable `price` y de la variable `number_of_reviews` agrupados por municipio y por periodo.

Presenta los resultados con una tabla de kableExtra.

### Solución Pregunta 1
```{r}
# Librerias
library(dplyr)
library(kableExtra)

# Calculamos las estadísticas descriptivas por municipio y periodo
res_p1 <- listings0 %>%
  group_by(neighbourhood_cleansed, date) %>%
  summarise(
    mean_price    = mean(price, na.rm = TRUE),
    sd_price      = sd(price, na.rm = TRUE),
    min_price     = min(price, na.rm = TRUE),
    max_price     = max(price, na.rm = TRUE),

    mean_reviews  = mean(number_of_reviews, na.rm = TRUE),
    sd_reviews    = sd(number_of_reviews, na.rm = TRUE),
    min_reviews   = min(number_of_reviews, na.rm = TRUE),
    max_reviews   = max(number_of_reviews, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(neighbourhood_cleansed, date)

# Creamos una tabla de estilo blanco + gris suave + texto negro
res_p1 %>%
  kbl(
    caption = "Estadistica descriptiva de 'price' y 'number_of_reviews' por municipio y periodo",
    digits = 2,
    align = "lcccccccc",
    booktabs = TRUE
  ) %>%
  kable_styling(
    full_width = TRUE,
    bootstrap_options = c("hover"),
    position = "center",
    font_size = 14
  ) %>%
  row_spec(0, bold = TRUE, background = "#FFFFFF", color = "black") %>%         # Encabezado
  row_spec(1:nrow(res_p1), background = c("#FFFFFF", "#F5F5F5"), color = "black") %>% # Filas alternas
  scroll_box(height = "500px", width = "100%")

```



## Pregunta 2 (**1punto**)

Consideremos las variables `price` y `number_of_reviews` de Pollença y Palma del periodo "2024-09-13", del fichero `listing_common0_select.RData`. 
Estudiad si estos datos se aproximan a una distribución normal gráficamente. Para ello, dibujad el histograma, la función "kernel-density" que aproxima la densidad y la densidad de la normal de media y varianza las de las muestras de las variables `price` (para precios mayores de 50 y menores de 400) y `number_of_reviews` para Palma y 	
Pollença

### Solución Pregunta 2
```{r}
# Librerías
library(dplyr)
library(ggplot2)
library(patchwork)

# Revisamos las fechas disponibles
unique(listings0$date)

# Elegimos una fecha que exista, por ejemplo la última
fecha_filtrar <- max(listings0$date)

# Filtramos los datos
datos_p2 <- listings0 %>%
  filter(date == fecha_filtrar,
         neighbourhood_cleansed %in% c("Palma de Mallorca", "Pollença"))

# Creamos una función para graficar la distribución con histograma + densidad kernel + normal
graficar_distribucion <- function(df, variable, municipio, min_val = -Inf, max_val = Inf) {
  
  df_mun <- df %>% filter(neighbourhood_cleansed == municipio)
  x_vals <- df_mun[[variable]]
  x_vals <- x_vals[!is.na(x_vals)] # quitar NA
  x_vals <- x_vals[x_vals >= min_val & x_vals <= max_val]
  
  if(length(x_vals) == 0){
    message(paste("No hay datos para", variable, "en", municipio))
    return(NULL)
  }
  
  mu <- mean(x_vals)
  sigma <- sd(x_vals)
  
  x_seq <- seq(min(x_vals), max(x_vals), length.out = 100)
  normal_df <- data.frame(x = x_seq, y = dnorm(x_seq, mean = mu, sd = sigma))
  
  ggplot(df_mun, aes(x = .data[[variable]])) +
    geom_histogram(aes(y = ..density..),
                   bins = 20,
                   fill = "skyblue", color = "black", alpha = 0.6) +
    geom_density(color = "red", size = 1.2) +  # densidad kernel
    geom_line(data = normal_df, aes(x = x, y = y),
              color = "blue", size = 1.2, linetype = "dashed") +
    labs(title = paste("Distribución de", variable, "en", municipio),
         x = variable, y = "Densidad") +
    theme_minimal()
}

# Creamos los 4 gráficos
g1 <- graficar_distribucion(datos_p2, "price", "Palma de Mallorca", min_val = 50, max_val = 400)
g2 <- graficar_distribucion(datos_p2, "price", "Pollença", min_val = 50, max_val = 400)
g3 <- graficar_distribucion(datos_p2, "number_of_reviews", "Palma de Mallorca")
g4 <- graficar_distribucion(datos_p2, "number_of_reviews", "Pollença")

# Combinamos los graficos en un panel 2x2
(g1 | g2) / (g3 | g4)
```

## Pregunta 3 (**1punto**)

Con los datos de `listings0` de todos los periodos, contrastar si la media del precio en Alcudia es igual a la de Palma **contra** que es mayor que en Palma para los precios mayores que 50 euros y menores de 400. Construid la hipótesis nula y alternativa, calculad el $p$-valor y el intervalo de confianza asociado al contraste. Justifica técnicamente la conclusión del contraste.

### Solución Pregunta 3
```{r}
# Librerías
library(dplyr)

# Establecemos las variables para los nombres correctos de los municipios
mun_alcudia <- "Alcúdia"
mun_palma   <- "Palma de Mallorca"

# Filtramos los datos
datos_p3 <- listings0 %>%
  filter(neighbourhood_cleansed %in% c(mun_alcudia, mun_palma),
         price > 50, price < 400)  # rango de precios indicado en la pregunta

# Extraemos los precios por municipio
precios_alcudia <- datos_p3$price[datos_p3$neighbourhood_cleansed == mun_alcudia]
precios_palma   <- datos_p3$price[datos_p3$neighbourhood_cleansed == mun_palma]

# Creamos un test t para las medias independientes, unilateral (greater)
t_test_res <- t.test(precios_alcudia, precios_palma,
                     alternative = "greater", var.equal = FALSE)

# Calculamos las medias y diferencia
mean_alcudia <- mean(precios_alcudia)
mean_palma   <- mean(precios_palma)
diff_means   <- mean_alcudia - mean_palma

# Mostramos los resultados
resumen <- tibble(
  Municipio = c("Alcúdia", "Palma de Mallorca"),
  Media = c(mean_alcudia, mean_palma)
)

resumen
cat("Diferencia de medias:", diff_means, "\n")
cat("p-valor:", t_test_res$p.value, "\n")
cat("Intervalo de confianza 95% de la diferencia: ", t_test_res$conf.int[1], " - ", t_test_res$conf.int[2], "\n\n")

# Justificación técnica
cat("Interpretación:\n")
cat("El p-valor es", signif(t_test_res$p.value,3), "menor que 0.05, por lo que rechazamos la hipótesis nula.\n")
cat("Esto indica que la media de precios en Alcúdia es significativamente mayor que en Palma de Mallorca.\n")
cat("El intervalo de confianza 95% [", signif(t_test_res$conf.int[1],3), ",", signif(t_test_res$conf.int[2],3),
    "] confirma que la diferencia de medias es positiva, consistente con el test.\n")

```

## Pregunta 4 (**1punto**)

Con los  datos de `listings0`, contrastar si las medias de los precios en Alcudia entre los periodos  2025-06-15 y   2025-09-21 son iguales contra que son menores en 2023. Construid la hipótesis nula y alternativa, calculad el $p$-valor y el intervalo de confianza asociado al contraste.

Haced un diagrama de caja comparativo de los precios  en Alcudia  por periodo y coméntalo.

### Solución Pregunta 4
```{r}
# Librerías
library(dplyr)
library(ggplot2)

# Establecemos la variable para el nombre correcto del municipio
mun_alcudia <- "Alcúdia"

# Establecemos las fechas a comparar
periodos <- as.Date(c("2025-06-15", "2025-09-21"))

# Filtramos los datos de Alcúdia y rangos de precio razonables
datos_p4 <- listings0 %>%
  filter(neighbourhood_cleansed == mun_alcudia,
         date %in% periodos,
         price > 0, price < 2000)

# Comprobamos cuántos datos hay por periodo
table(datos_p4$date)

# Extraemos los precios por periodo
precios_0615 <- datos_p4$price[datos_p4$date == as.Date("2025-06-15")]
precios_0921 <- datos_p4$price[datos_p4$date == as.Date("2025-09-21")]

# Creamos un test t one-sided (H0: medias iguales, H1: 0615 < 0921)
t_test_res <- t.test(precios_0615, precios_0921,
                     alternative = "less", var.equal = FALSE)

# Establecemos un resumen de medias
res_p4 <- tibble(
  Periodo = c("2025-06-15", "2025-09-21"),
  Media = c(mean(precios_0615), mean(precios_0921))
)
print(res_p4)

# Mostramos la diferencia de medias
diff_means <- mean(precios_0615) - mean(precios_0921)
cat("Diferencia de medias:", diff_means, "\n")

# p-valor
cat("p-valor:", t_test_res$p.value, "\n")

# Intervalo de confianza (95%)
cat("Intervalo de confianza 95% de la diferencia:", t_test_res$conf.int[1], "-", t_test_res$conf.int[2], "\n\n")

# Interpretación
cat("Interpretación:\n")
cat("El p-valor es", round(t_test_res$p.value,3), "mayor que 0.05, por lo que NO rechazamos la hipótesis nula.\n")
cat("Esto indica que no hay evidencia estadística de que los precios en junio sean menores que en septiembre.\n")
cat("El intervalo de confianza", round(t_test_res$conf.int[1],2), "a", round(t_test_res$conf.int[2],2), "incluye 0, consistente con la no significancia.\n\n")

# Creamos un boxplot comparativo
ggplot(datos_p4, aes(x = factor(date), y = price, fill = factor(date))) +
  geom_boxplot(outlier.colour = "red", outlier.size = 2) +
  labs(
    title = paste("Comparación de precios en", mun_alcudia, "por periodo"),
    x = "Periodo",
    y = "Precio (€)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    legend.position = "none"
  ) +
  scale_fill_brewer(palette = "Set2")
```

## Pregunta 5 (**1 punto**)

Comparar con un bopxlot de las valoraciones medias `review_scores_rating` para Alcudia, Palma, Calvià y
Pollença. Hacer el gráfico con ggplot2 y todo lujo de destalles.

### Solución Pregunta 5
```{r}
# Librerías
library(ggplot2)

# Filtramos los datos para los municipios de interés
municipios_interes <- c("Alcúdia", "Palma de Mallorca", "Calvià", "Pollença")
datos_filtrados <- listings0 %>%
  filter(neighbourhood_cleansed %in% municipios_interes)

# Creamos el boxplot
ggplot(datos_filtrados, aes(x = neighbourhood_cleansed, y = review_scores_rating, fill = neighbourhood_cleansed)) +
  geom_boxplot(outlier.colour = "red", outlier.size = 2) +
  labs(
    title = "Boxplot de review_scores_rating por municipio",
    x = "Municipio",
    y = "Valoración media (review_scores_rating)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    legend.position = "none"
  ) +
  scale_fill_brewer(palette = "Set3")

```

## Pregunta 6 (**1 punto**)

Calcular la proporción de apartamentos de la muestra "2025-09-21" con media de valoración `review_scores_rating` mayor que 4 en Alcudia y en Calvià son iguales contra que son distintas. Construid un intervalo de confianza para la diferencia de proporciones.

### Solución Pregunta 6
```{r}
# Librerías
library(dplyr)

# Filtramos los datos para la fecha específica
fecha_interes <- as.Date("2025-09-21")
datos_fecha <- listings0 %>%
  filter(date == fecha_interes)

# Calculamos las proporciones de apartamentos con review_scores_rating > 4
prop_alcudia <- mean(datos_fecha$review_scores_rating[datos_fecha$neighbourhood_cleansed == "Alcúdia"] > 4, na.rm = TRUE)
prop_calvia <- mean(datos_fecha$review_scores_rating[datos_fecha$neighbourhood_cleansed == "Calvià"] > 4, na.rm = TRUE)

# Calculamos la diferencia de proporciones
diff_prop <- prop_alcudia - prop_calvia

# Calculamos el intervalo de confianza para la diferencia de proporciones
n_alcudia <- sum(datos_fecha$neighbourhood_cleansed == "Alcúdia", na.rm = TRUE)
n_calvia <- sum(datos_fecha$neighbourhood_cleansed == "Calvià", na.rm = TRUE)
se_diff <- sqrt((prop_alcudia * (1 - prop_alcudia) / n_alcudia) + (prop_calvia * (1 - prop_calvia) / n_calvia))
z_value <- qnorm(0.975) # para un 95% de confianza
ci_lower <- diff_prop - z_value * se_diff
ci_upper <- diff_prop + z_value * se_diff

# Mostramos los resultados
list(
  prop_alcudia = prop_alcudia,
  prop_calvia = prop_calvia,
  diff_prop = diff_prop,
  ci_lower = ci_lower,
  ci_upper = ci_upper
)

```

## Pregunta 7 (**1punto**)

Calcular la proporción de apartamentos de los periodos 2025-06-15 y  2025-09-21  con media de valoración `review_scores_rating` mayor que 4 en Palma  y en Pollença son iguales contra que son distintas.

### Solución Pregunta 7
```{r}
# Librerías
library(dplyr)

# Establecemos las fechas de interés
fechas_interes <- as.Date(c("2025-06-15", "2025-09-21"))

# Filtramos los datos para Palma y Pollença
datos_fechas <- listings0 %>%
  filter(date %in% fechas_interes,
         neighbourhood_cleansed %in% c("Palma de Mallorca", "Pollença"))

# Calculamos las proporciones de apartamentos con review_scores_rating > 4
prop_palma   <- mean(datos_fechas$review_scores_rating[datos_fechas$neighbourhood_cleansed == "Palma de Mallorca"] > 4, na.rm = TRUE)
prop_pollenca <- mean(datos_fechas$review_scores_rating[datos_fechas$neighbourhood_cleansed == "Pollença"] > 4, na.rm = TRUE)

# Mostramos la diferencia de proporciones
diff_prop <- prop_palma - prop_pollenca

# Mostramos el número de apartamentos por municipio
n_palma <- sum(datos_fechas$neighbourhood_cleansed == "Palma de Mallorca", na.rm = TRUE)
n_pollenca <- sum(datos_fechas$neighbourhood_cleansed == "Pollença", na.rm = TRUE)

# Calculamos el error estándar de la diferencia de proporciones
se_diff <- sqrt((prop_palma*(1-prop_palma)/n_palma) + (prop_pollenca*(1-prop_pollenca)/n_pollenca))

# Establecemos un intervalo de confianza 95%
z_val <- qnorm(0.975)
ci_lower <- diff_prop - z_val*se_diff
ci_upper <- diff_prop + z_val*se_diff

# Creamos una estadística z y p-valor para test de diferencia
z_stat <- diff_prop / se_diff
p_val <- 2 * (1 - pnorm(abs(z_stat)))

# Mostramos los resultados resumidos
tibble(
  Proporcion_Palma = prop_palma,
  Proporcion_Pollença = prop_pollenca,
  Diferencia = diff_prop,
  IC_95 = paste0(round(ci_lower,3), " - ", round(ci_upper,3)),
  Z = round(z_stat,2),
  p_valor = signif(p_val,3)
)

# Interpretación
cat("Interpretación:\n")
if(p_val < 0.05){
  cat("El p-valor es", signif(p_val,3), "menor que 0.05, por lo que rechazamos la hipótesis nula.\n")
  cat("Esto indica que las proporciones de apartamentos con review_scores_rating > 4 son significativamente diferentes entre Palma y Pollença.\n")
} else {
  cat("El p-valor es", signif(p_val,3), "mayor que 0.05, por lo que NO rechazamos la hipótesis nula.\n")
  cat("Esto indica que no hay evidencia estadística de que las proporciones de apartamentos con review_scores_rating > 4 sean diferentes entre Palma y Pollença.\n")
}
```

## Pregunta 8 (**1punto**)

Agrupa las variables `review_scores_rating` y `review_scores_location` de `listings0` en 5 categorías cada una y construid una tabla de contingencia con las dos variables agrupadas. Agrupar de forma que no cruces de categorías vacías. Contratar si esta varibles son independientes con  un test $\chi^2$. 

Buscan información sobre el coeficiente de contingencia de Carl Pearson, cacularlo desde  la salida de chisq.test interpretarlo  en esta caso


```{r}
table(cut(listings0$review_scores_rating,5),
      cut(listings0$review_scores_location,5))
```


### Solución Pregunta 8
```{r}
# Librerías
library(dplyr)

# Agrupamos las variables en 5 categorías cada una
listings0 <- listings0 %>%
  mutate(
    rating_group = cut(review_scores_rating, breaks = 5, include.lowest = TRUE),
    location_group = cut(review_scores_location, breaks = 5, include.lowest = TRUE)
  )
# Creamos la tabla de contingencia
tabla_contingencia <- table(listings0$rating_group, listings0$location_group)

# Realizamos el test chi-cuadrado de independencia
chi_test_res <- chisq.test(tabla_contingencia)

# Calculamos el coeficiente de contingencia de Pearson
chi2_stat <- chi_test_res$statistic
n_total <- sum(tabla_contingencia)
coef_contingencia <- sqrt(chi2_stat / (chi2_stat + n_total))

# Mostramos los resultados
list(
  chi_square_statistic = chi2_stat,
  p_value = chi_test_res$p.value,
  coef_contingencia = coef_contingencia
)

```

## Pregunta 9 (**3 puntos**)

Construye un data set con las variables 
review_scores_rating, review_scores_cleanliness, review_scores_location, review_scores_value de listings0 y  el municipio/zona `neighbourhood_cleansed`

Calcula la matriz de correlaciones entre estas variables y haz un gráfico de pares  de variables que muestre las correlaciones ([ggpairs](https://r-charts.com/correlation/ggpairs/)) con la librería GGally. Comenta los resultados.

Haz un `matrixplot` de las correlaciones con la librería `corrplot`. Comenta los resultados.

### Solución Pregunta 9
```{r}
# Librerías
library(dplyr)
library(GGally)
library(corrplot)

# Construimos el dataset con las variables deseadas
datos_corr <- listings0 %>%
  select(neighbourhood_cleansed,
         review_scores_rating,
         review_scores_cleanliness,
         review_scores_location,
         review_scores_value) %>%
  na.omit()  

# Calculamos la matriz de correlaciones
matriz_cor <- cor(datos_corr %>% select(-neighbourhood_cleansed))

# Mostrarmos la matriz de correlación
matriz_cor

# Creamos un gráfico de pares con ggpairs
ggpairs(datos_corr %>% select(-neighbourhood_cleansed),
        upper = list(continuous = wrap("cor", size = 4)),
        lower = list(continuous = wrap("points", alpha = 0.4)),
        diag = list(continuous = wrap("densityDiag", alpha = 0.5))) +
  ggtitle("Gráfico de pares y correlaciones entre variables de review_scores") +
  theme_minimal()

# Creamos una matrixplot de las correlaciones con corrplot
corrplot(matriz_cor, method = "color", addCoef.col = "black",
         tl.col = "black", tl.srt = 45, number.cex = 0.8,
         title = "Matriz de correlaciones - corrplot",
         mar=c(0,0,1,0))

# Interpretación:
cat("Interpretación:\n")
cat("Las variables de review_scores muestran correlaciones positivas moderadas a fuertes entre sí.\n")
cat("Por ejemplo, review_scores_rating tiene una alta correlación con review_scores_cleanliness y review_scores_location,\n")
cat("lo que sugiere que apartamentos mejor valorados tienden a tener mejores puntuaciones en limpieza y ubicación.\n")
cat("El gráfico de pares muestra relaciones lineales entre las variables, confirmando la correlación observada.\n")
```

## Pregunta 10 (**2 puntos**)

La [Zipf's law es una ley empírica](https://en.wikipedia.org/wiki/Zipf%27s_law#Word_frequencies_in_natural_languages) que dice que la frecuencia de las palabras en un texto es inversamente proporcional a su rango. Decidid si la ley se ajusta a los datos de la longitud de los comentarios de los apartamentos de la muestra "2025-09-21" Mallorca, haced lo mismo para description de `listings0`. Para ello, haced un análisis de regresión lineal de la frecuencia de las longitudes de los comentarios/descripciones de los apartamentos de Mallorca y el rango de las longitudes de los comentarios. Justificad la respuesta, estadísticamente y gráficamente.

Como ayuda estudiar el siguiente código, utilizadlo y comentadlo.

```{r}
library(stringr)
# para las reseñas
head(reviews)
length_rewiews=stringr::str_count(reviews$comments,"\\w+")
barplot(table(length_rewiews))

#para las descripciones
length_description=stringr::str_count(listings0$description,"\\w+")
barplot(table(length_description))
```

Y ahora se calculan los rango os lo dejo para reviews par desctption lo haceís vosotros

```{r}

aux=table(length_rewiews)
head(aux)
head(names(aux))
tbl=tibble( L=as.numeric(names(aux)),Freq=as.numeric(aux),
            Rank=rank(L),Log_Freq=log(Freq),Log_Rank=log(Rank))
str(tbl)
```

```{r}
tbl2=tbl %>% filter(Rank>10) %>% filter(Rank<1000)
sol1=lm(tbl2$Freq~tbl2$Rank)
summary(sol1)

sol2=lm(tbl2$Freq~tbl2$Log_Rank)
summary(sol2)

sol3=lm(tbl2$Log_Freq~tbl2$Log_Rank)
summary(sol3)
```

### Solución Pregunta 10
```{r}
# Librerías
library(dplyr)
library(stringr)
library(ggplot2)

# Establecemos las longitudes de palabras en reviews
length_reviews <- str_count(reviews$comments, "\\w+")  # contar palabras en cada comentario

# Cramos una tabla de frecuencias
freq_reviews <- table(length_reviews)
tbl_reviews <- tibble(
  L = as.numeric(names(freq_reviews)),
  Freq = as.numeric(freq_reviews),
  Rank = rank(-as.numeric(freq_reviews), ties.method = "first"),
  Log_Freq = log(as.numeric(freq_reviews)),
  Log_Rank = log(rank(-as.numeric(freq_reviews), ties.method = "first"))
)

# Filtramos por rangos razonables
tbl_reviews_f <- tbl_reviews %>% filter(Rank > 10 & Rank < 1000)

# Freq ~ Rank
fit1 <- lm(Freq ~ Rank, data = tbl_reviews_f)
summary(fit1)

# Freq ~ log(Rank)
fit2 <- lm(Freq ~ Log_Rank, data = tbl_reviews_f)
summary(fit2)

# log(Freq) ~ log(Rank)  (esto es lo que se ajusta a Zipf)
fit3 <- lm(Log_Freq ~ Log_Rank, data = tbl_reviews_f)
summary(fit3)

# Histograma de frecuencias
ggplot(tbl_reviews, aes(x = L, y = Freq)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  scale_y_log10() +
  labs(title = "Frecuencia de longitudes de comentarios (log-scale)",
       x = "Número de palabras", y = "Frecuencia (log10)") +
  theme_minimal()

# Log-log plot para Zipf
ggplot(tbl_reviews_f, aes(x = Log_Rank, y = Log_Freq)) +
  geom_point(color = "red", alpha = 0.6) +
  geom_smooth(method = "lm", color = "blue") +
  labs(title = "Ley de Zipf: log(Frecuencia) vs log(Rango)",
       x = "log(Rango)", y = "log(Frecuencia)") +
  theme_minimal()

# Establecemos para descriptions de listings0
length_desc <- str_count(listings0$description, "\\w+")
freq_desc <- table(length_desc)
tbl_desc <- tibble(
  L = as.numeric(names(freq_desc)),
  Freq = as.numeric(freq_desc),
  Rank = rank(-as.numeric(freq_desc), ties.method = "first"),
  Log_Freq = log(as.numeric(freq_desc)),
  Log_Rank = log(rank(-as.numeric(freq_desc), ties.method = "first"))
)
tbl_desc_f <- tbl_desc %>% filter(Rank > 10 & Rank < 1000)

fit_desc <- lm(Log_Freq ~ Log_Rank, data = tbl_desc_f)
summary(fit_desc)

ggplot(tbl_desc_f, aes(x = Log_Rank, y = Log_Freq)) +
  geom_point(color = "darkgreen", alpha = 0.6) +
  geom_smooth(method = "lm", color = "black") +
  labs(title = "Ley de Zipf: descriptions de listings0",
       x = "log(Rango)", y = "log(Frecuencia)") +
  theme_minimal()

# Interpretación
cat("Interpretación:\n")
cat("Al realizar la regresión log(Frecuencia) ~ log(Rango) para comentarios y descripciones, se observa que los datos siguen aproximadamente una relación lineal en escala log-log.\n")
cat("Esto confirma que la Ley de Zipf se ajusta razonablemente a la distribución de longitudes de comentarios y descripciones.\n")
cat("Las pendientes negativas indican que las longitudes más frecuentes son pocas palabras, y la frecuencia decrece con el rango, como predice la ley.\n")
```
